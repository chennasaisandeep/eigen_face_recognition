{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.11'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run only once\n",
    "pip install opencv-python==3.4.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for image capture frequency, resize factor, and number of training images\n",
    "FREQ_DIV = 5   \n",
    "RESIZE_FACTOR = 4\n",
    "NUM_TRAINING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEigenFaces:\n",
    "    \"\"\"\n",
    "    Class for training a face recognition model using Eigenfaces in OpenCV.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "        self.face_cascade = cv2.CascadeClassifier(cascPath)\n",
    "        self.face_dir = 'face_data'\n",
    "        self.face_name = input(\"Name of the person face: \")\n",
    "        self.path = os.path.join(self.face_dir, self.face_name)\n",
    "        print(self.path)\n",
    "        if not os.path.isdir(self.path):\n",
    "            print(\"creating path\")\n",
    "            os.mkdir(self.path)\n",
    "        self.count_captures = 0\n",
    "        self.count_timer = 0\n",
    "\n",
    "    def capture_training_images(self):\n",
    "        \"\"\"\n",
    "        Capture training images from the webcam.\n",
    "        \"\"\"\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            self.count_timer += 1\n",
    "            ret, frame = video_capture.read()\n",
    "            inImg = np.array(frame)\n",
    "            outImg = self.process_image(inImg)\n",
    "            cv2.imshow('Video', outImg)\n",
    "\n",
    "            # When everything is done, release the capture on pressing 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                video_capture.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "\n",
    "\n",
    "    def process_image(self, inImg):\n",
    "        \"\"\"\n",
    "        Process an image: flip it, convert to grascale, resize and detect faces.\n",
    "        \"\"\"\n",
    "        frame = cv2.flip(inImg,1)\n",
    "        resized_width, resized_height = (92, 112)        \n",
    "        if self.count_captures < NUM_TRAINING:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "            gray_resized = cv2.resize(gray, (int(gray.shape[0]/RESIZE_FACTOR),int(gray.shape[1]/RESIZE_FACTOR)))        \n",
    "            faces = self.face_cascade.detectMultiScale(\n",
    "                gray_resized,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "                )\n",
    "            if len(faces) > 0:\n",
    "                areas = []\n",
    "                for (x, y, w, h) in faces: \n",
    "                    areas.append(w*h)\n",
    "                max_area, idx = max([(val,idx) for idx,val in enumerate(areas)])\n",
    "                face_sel = faces[idx]\n",
    "            \n",
    "                x = face_sel[0] * RESIZE_FACTOR\n",
    "                y = face_sel[1] * RESIZE_FACTOR\n",
    "                w = face_sel[2] * RESIZE_FACTOR\n",
    "                h = face_sel[3] * RESIZE_FACTOR\n",
    "\n",
    "                # Ensure the face region is within image boundaries\n",
    "                y_start = max(0, y-h//2-30)\n",
    "                y_end = min(gray.shape[0], y+h//2+30)\n",
    "                x_start = max(0, x+80)\n",
    "                x_end = min(gray.shape[1], x+w+80)\n",
    "\n",
    "                face = gray[y_start:y_end, x_start:x_end]\n",
    "                face_resized = cv2.resize(face, (resized_width, resized_height))\n",
    "                img_no = sorted([int(fn[:fn.find('.')]) for fn in os.listdir(self.path) if fn[0]!='.' ]+[0])[-1] + 1\n",
    "                \n",
    "                if self.count_timer%FREQ_DIV == 0:\n",
    "                    if face.size != 0:\n",
    "                        cv2.imwrite('%s/%s.png' % (self.path, img_no), face_resized)\n",
    "                        self.count_captures += 1\n",
    "                        print(\"Captured image: \", self.count_captures)\n",
    "\n",
    "                cv2.rectangle(frame, (x_start, y_start), (x_end, y_end), (0, 255, 0), 3)\n",
    "                cv2.putText(frame, self.face_name, (x - 10, y - 10), cv2.FONT_HERSHEY_PLAIN, 1,(0, 255, 0))\n",
    "        elif self.count_captures == NUM_TRAINING:\n",
    "            print(\"Training data captured. Press 'q' to exit.\")\n",
    "            self.count_captures += 1\n",
    "\n",
    "        return frame\n",
    "    \n",
    "    def form_face_matrix(self, data, labels, tag, num_images = 20):\n",
    "        \"\"\"\n",
    "        Form a matrix of face images for a given tag.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: Images data.\n",
    "        - labels: Labels for the images.\n",
    "        - tag: Tag identifying the person.\n",
    "        - num_images: Number of images to consider.\n",
    "        \n",
    "        Returns:\n",
    "        - face_images: Matrix of face images for the given tag.\n",
    "        \"\"\"\n",
    "        face_indices = np.where(labels == tag)[0]\n",
    "        face_images = data[face_indices].reshape(num_images, -1).T\n",
    "        return face_images\n",
    "\n",
    "    def compute_eigenfaces(self):\n",
    "        \"\"\"\n",
    "        Compute eigenfaces for face recognition.\n",
    "        \n",
    "        Returns:\n",
    "        - faces_svd_component: Singular value decomposition components of face matrices.\n",
    "        \"\"\"\n",
    "        imgs = []\n",
    "        tags = []\n",
    "        index = 0\n",
    "        for (subdirs, dirs, files) in os.walk(self.face_dir):\n",
    "            for subdir in dirs:\n",
    "                img_path = os.path.join(self.face_dir, subdir)\n",
    "                for fn in os.listdir(img_path):\n",
    "                    path = img_path + '/' + fn\n",
    "                    tag = index\n",
    "                    imgs.append(cv2.imread(path, 0))\n",
    "                    tags.append(int(tag))\n",
    "                index += 1\n",
    "        (imgs, tags) = [np.array(item) for item in [imgs, tags]]\n",
    "        \n",
    "        face_matrices = [self.form_face_matrix(imgs, tags, person) for person in range(len([name for name in os.listdir(self.face_dir) if os.path.isdir(os.path.join(self.face_dir, name))]))]\n",
    "        faces_svd_component = [np.linalg.svd(matrix, full_matrices=False)[0] for matrix in face_matrices]\n",
    "        with open('faces_svd', 'wb') as fp:\n",
    "            pickle.dump(faces_svd_component, fp)\n",
    "        return faces_svd_component\n",
    "    \n",
    "\n",
    "trainer = TrainEigenFaces()\n",
    "trainer.capture_training_images()\n",
    "trainer.compute_eigenfaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecogEigenFaces():\n",
    "    \"\"\"\n",
    "    Class for recognizing faces using Eigenfaces.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "        self.face_cascade = cv2.CascadeClassifier(cascPath)\n",
    "        self.face_dir = 'face_data'\n",
    "        self.face_names = []\n",
    "        with open('faces_svd', 'rb') as fp:\n",
    "            self.U = pickle.load(fp)\n",
    "    \n",
    "    def load_trained_data(self):\n",
    "        \"\"\"\n",
    "        Load the names of individuals from the training dataset.\n",
    "        \"\"\"\n",
    "        names = {}\n",
    "        key = 0\n",
    "        for (subdirs, dirs, files) in os.walk(self.face_dir):\n",
    "            for subdir in dirs:\n",
    "                names[key] = subdir\n",
    "                key += 1\n",
    "        self.names = names \n",
    "\n",
    "    def show_video(self):\n",
    "        \"\"\"\n",
    "        Capture video stream from the webcam and recognize faces in real-time.\n",
    "        \"\"\"\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "            inImg = np.array(frame)\n",
    "            outImg, self.face_names = self.process_image(inImg)\n",
    "            cv2.imshow('Video', outImg)\n",
    "\n",
    "            # When everything is done, release the capture on pressing 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                video_capture.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "            \n",
    "    def classify_image(self, z, Us):\n",
    "        \"\"\"\n",
    "        Classify a face image by finding the closest match using eigenfaces.\n",
    "        \n",
    "        Parameters:\n",
    "        - z: Eigenface representation of the input face image.\n",
    "        - Us: List of eigenface spaces.\n",
    "        \n",
    "        Returns:\n",
    "        - label: Index of the closest match in the eigenfaces list.\n",
    "        - min_distance: Minimum distance between the input image and the closest eigenface space.\n",
    "        \"\"\"\n",
    "        min_distance = float(\"inf\")\n",
    "        label = None\n",
    "        \n",
    "        for n, U in enumerate(Us):\n",
    "            projection = U @ (U.T @ z.reshape(-1))\n",
    "            distance = np.linalg.norm(z.reshape(-1)-projection)\n",
    "            \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                label = n\n",
    "        print(label, min_distance)\n",
    "        return label, min_distance\n",
    "\n",
    "    def process_image(self, inImg):\n",
    "        \"\"\"\n",
    "        Detect faces in the input image, recognize them, and annotate the image accordingly.\n",
    "        \n",
    "        Parameters:\n",
    "        - inImg: Input image frame from the video stream.\n",
    "        \n",
    "        Returns:\n",
    "        - frame: Annotated image with recognized faces.\n",
    "        - persons: List of names corresponding to the recognized faces.\n",
    "        \"\"\"\n",
    "        frame = cv2.flip(inImg,1)\n",
    "        resized_width, resized_height = (92, 112)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)        \n",
    "        gray_resized = cv2.resize(gray, (int(gray.shape[0]/RESIZE_FACTOR),int(gray.shape[1]/RESIZE_FACTOR)))\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "                gray_resized,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "                )\n",
    "        persons = []\n",
    "        for i in range(len(faces)):\n",
    "            face_i = faces[i]\n",
    "            x = face_i[0] * RESIZE_FACTOR\n",
    "            y = face_i[1] * RESIZE_FACTOR\n",
    "            w = face_i[2] * RESIZE_FACTOR\n",
    "            h = face_i[3] * RESIZE_FACTOR\n",
    "            \n",
    "            # Ensure the face region is within image boundaries\n",
    "            y_start = max(0, y-h//2-30)\n",
    "            y_end = min(gray.shape[0], y+h//2+30)\n",
    "            x_start = max(0, x+80)\n",
    "            x_end = min(gray.shape[1], x+w+80)\n",
    "                \n",
    "            face = gray[y_start:y_end, x_start:x_end]\n",
    "            face_resized = cv2.resize(face, (resized_width, resized_height))\n",
    "            confidence = self.classify_image(face_resized, self.U)\n",
    "            if confidence[1]<5000:\n",
    "                person = self.names[confidence[0]]\n",
    "                cv2.rectangle(frame, (x_start, y_start), (x_end, y_end), (0, 255, 0), 3)\n",
    "                cv2.putText(frame, '%s - %.0f' % (person, confidence[1]), (x+w-20, y+h-40), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))\n",
    "            else:\n",
    "                person = 'Unknown'\n",
    "                cv2.rectangle(frame, (x_start, y_start), (x_end, y_end), (255, 0, 0), 3)\n",
    "                cv2.putText(frame, person, (x+w-20, y+h-40), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))\n",
    "            persons.append(person)\n",
    "        return (frame, persons)\n",
    "\n",
    "recognizer = RecogEigenFaces()\n",
    "recognizer.load_trained_data()\n",
    "print(\"Press 'q' to quit video\")\n",
    "recognizer.show_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
